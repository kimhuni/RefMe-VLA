# ğŸ“¦ dataset_vlm.py (V5 Architecture - FINALIZED)
# V6ì˜ pre-caching ëŒ€ì‹ , V5ì˜ process-local ì•„í‚¤í…ì²˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë“  ë²„ê·¸ë¥¼ ìˆ˜ì •í•œ ìµœì¢…ë³¸ì…ë‹ˆë‹¤.
# 'train_vlm.py'ì˜ 'dataloader_num_workers=16' (ì´ìƒ)ê³¼ í•¨ê»˜ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.

import json
import os
import glob
import torch
from torch.utils.data import Dataset
from transformers import AutoProcessor
from PIL import Image
import logging
from dataclasses import dataclass
from torch.nn.utils.rnn import pad_sequence

# ë¡œê±° ì„¤ì • (Dataloader ì›Œì»¤ì—ì„œ ë¡œê¹…í•˜ë ¤ë©´ ì¤‘ìš”)
logger = logging.getLogger(__name__)


# (ì°¸ê³ : train_vlm.pyì—ì„œ logging.basicConfigë¥¼ í˜¸ì¶œí•´ì•¼ í•¨)


def make_train_prompt(task: str, prev: str, prev_status: str) -> str:
    """
    Generate a concise training prompt for image analysis in robot manipulation.
    (í›ˆë ¨/ì¶”ë¡  ì‹œ ë™ì¼í•˜ê²Œ ì‚¬ìš©)
    """
    return (
        "You are an image-analysis expert for robot manipulation.\n"
        "INPUT_IMAGES: [SIDE]=global scene view; [WRIST]=close-up wrist camera.\n"
        f"TASK: {task}\n"
        f"PREV_DESC: {prev}\n"
        f"PREV_STATUS: {prev_status}\n"
        "Describe what is visibly happening now (desc_1) and the visible evidence for completion (desc_2).\n"
        "Then decide the status: DONE / NOT_DONE / UNCERTAIN.\n"
        "Output JSON: {\"desc_1\":\"...\",\"desc_2\":\"...\",\"status\":\"...\"}"
    )


# ===== 1) Dataset: V5 ì•„í‚¤í…ì²˜ (í”„ë¡œì„¸ìŠ¤-ë¡œì»¬) =====
class VlmDataset(Dataset):
    """
    [V5 Architecture]
    __init__ì€ ê°€ë³ê²Œ ê²½ë¡œë§Œ ë¡œë“œí•©ë‹ˆë‹¤. (ë¹ ë¥¸ ì‹œì‘)
    __getitem__ì´ Dataloader ì›Œì»¤(í”„ë¡œì„¸ìŠ¤)ë³„ë¡œ ì „ì²˜ë¦¬ë¥¼ ë³‘ë ¬ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """

    def __init__(self, dataset_dir: str, model_name_or_path: str):
        self.model_name_or_path = model_name_or_path
        self.data = []

        # 1. ìƒ¤ë“œ íŒŒì¼ ê²€ìƒ‰
        shard_pattern = os.path.join(dataset_dir, "shards", "chunk-*.json*")
        shard_files = sorted(glob.glob(shard_pattern))
        if not shard_files:
            raise FileNotFoundError(f"No shards found at {shard_pattern}")

        # 2. .jsonlì˜ *ë‚´ìš©*ì´ ì•„ë‹Œ *ê²½ë¡œì™€ ë¼ì¸ ë²ˆí˜¸*ë§Œ ë¡œë“œ (ì´ˆê²½ëŸ‰)
        # (V6ì™€ ë‹¬ë¦¬, ì—¬ê¸°ì„œ ëª¨ë“  ë°ì´í„°ë¥¼ RAMì— ì˜¬ë¦¬ì§€ ì•ŠìŠµë‹ˆë‹¤.)
        # [ìˆ˜ì •] ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ì„ ìœ„í•´, ë¼ì¸ë³„ë¡œ ì½ì§€ ì•Šê³  íŒŒì¼ ëª©ë¡ë§Œ ì €ì¥
        for shard_file in shard_files:
            try:
                with open(shard_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        if line.strip():
                            self.data.append(json.loads(line))
            except Exception as e:
                logger.warning(f"Error reading or parsing {shard_file}: {e}")

        logger.info(f"Loaded {len(self.data)} data points from {len(shard_files)} shards.")

        # 3. [V5] í”„ë¡œì„¸ì„œëŠ” ì›Œì»¤ë³„ë¡œ ìƒì„±ë˜ë„ë¡ Noneìœ¼ë¡œ ì´ˆê¸°í™”
        self.processor = None

    def __len__(self):
        return len(self.data)

    def _initialize_processor(self):
        """
        Dataloader ì›Œì»¤ë³„ë¡œ í”„ë¡œì„¸ì„œë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        """
        logger.info(f"Initializing processor for worker...")
        self.processor = AutoProcessor.from_pretrained(
            self.model_name_or_path,
            trust_remote_code=True,
            use_fast=True
        )
        if self.processor.tokenizer.pad_token is None:
            self.processor.tokenizer.pad_token = self.processor.tokenizer.eos_token

    def __getitem__(self, idx):
        """
        ì´ í•¨ìˆ˜ëŠ” 16ê°œ(num_workers)ì˜ í”„ë¡œì„¸ìŠ¤ì—ì„œ ë™ì‹œì— ë³‘ë ¬ ì‹¤í–‰ë©ë‹ˆë‹¤.
        """
        if self.processor is None:
            self._initialize_processor()

        item = self.data[idx]

        # --- 1. ì´ë¯¸ì§€ ë¡œë“œ ---
        try:
            images_list = [
                Image.open(item['images']['side']).convert('RGB'),
                Image.open(item['images']['wrist']).convert('RGB')
            ]
        except Exception as e:
            logger.error(f"Error loading images for {item.get('uid', idx)}: {e}")
            return {}  # ì½œë ˆì´í„°ê°€ ì´ ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¥¼ ë¬´ì‹œí•©ë‹ˆë‹¤.

        # --- 2. í…ìŠ¤íŠ¸ ìƒì„± ---
        user_prompt_text = make_train_prompt(
            item['task'], item.get('prev_desc', ''), item.get('prev_status', 'NOT_DONE')
        )
        target_text = json.dumps(item['api_output'])

        # --- 3. ì±„íŒ… í…œí”Œë¦¿ êµ¬ì„± ---
        messages = [
            {"role": "user",
             "content": [{"type": "image"}, {"type": "image"}, {"type": "text", "text": user_prompt_text}]},
            {"role": "assistant", "content": target_text}
        ]

        # --- 4. í† í°í™” (String ë³€í™˜ -> Processor í˜¸ì¶œ) ---
        # (AttributeError: 'dict' object has no attribute 'replace' ë²„ê·¸ ìˆ˜ì •)
        try:
            prompt_string = self.processor.tokenizer.apply_chat_template(
                messages,
                tokenize=False,
                add_generation_prompt=False  # ì´ë¯¸ assistant í„´ í¬í•¨
            )
        except Exception as e:
            logger.error(f"Error applying chat template for {item.get('uid', idx)}: {e}")
            return {}

        model_inputs = self.processor(
            text=prompt_string,  # ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ ë¬¸ìì—´ ì „ë‹¬
            images=images_list,
            return_tensors="pt",
            padding=False
        )

        input_ids = model_inputs['input_ids'][0]
        labels = input_ids.clone()
        attention_mask = model_inputs['attention_mask'][0]

        # --- 5. [FINAL MASKING LOGIC] ---
        # (loss=6, `,,` ì¶œë ¥ ë²„ê·¸ ìˆ˜ì •)
        # "ë’¤ì—ì„œë¶€í„° ê³„ì‚°"í•˜ëŠ” ë¡œì§ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

        # 1. ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ì‹¤ì œ ì‘ë‹µ(ì¤„ë°”ê¿ˆ + JSON)ì„ í† í°í™”
        assistant_content_str = "\n" + target_text
        target_tokens = self.processor.tokenizer(
            assistant_content_str, add_special_tokens=False
        ).input_ids

        # 2. ì‘ë‹µ ê¸¸ì´ = (ì¤„ë°”ê¿ˆ+JSON) í† í° + <|im_end|> í† í° 1ê°œ
        target_len = len(target_tokens) + 1  # +1 for <|im_end|>

        # 3. (ì „ì²´ ê¸¸ì´ - ì‘ë‹µ ê¸¸ì´) ë§Œí¼ì„ ë§ˆìŠ¤í‚¹
        mask_len = len(labels) - target_len

        if mask_len < 0:
            logger.warning(
                f"Masking error for {item.get('uid', idx)}: Target length ({target_len}) is longer than total input ({len(labels)}). Not masking.")
        else:
            labels[:mask_len] = -100

        # --- 6. [BUG FIX] `image_grid_thw` ì œê±° ---
        # (IndexError: 0-dim tensor ë²„ê·¸ ìˆ˜ì •)
        # Qwen2_5_VLì€ ì´ ì¸ìê°€ í•„ìš” ì—†ìœ¼ë©°, ì—ëŸ¬ë¥¼ ìœ ë°œí•©ë‹ˆë‹¤.

        return {
            "input_ids": input_ids,
            "attention_mask": attention_mask,
            "labels": labels,
        }


# ===== 2) Collator: í…ì„œë¥¼ ë°›ì•„ íŒ¨ë”©ë§Œ ìˆ˜í–‰ (V5ì™€ ë™ì¼, ë¹ ë¦„) =====
@dataclass
class DataCollatorForVLM:
    """
    VlmDatasetì—ì„œ ì´ë¯¸ í…ì„œë¡œ ë³€í™˜ëœ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°›ì•„ íŒ¨ë”©ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    tokenizer: AutoProcessor  # pad_token_idë¥¼ ì–»ê¸° ìœ„í•´ í”„ë¡œì„¸ì„œ ì „ì²´ë¥¼ ë°›ìŒ

    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, torch.Tensor]:
        # __getitem__ì—ì„œ ì—ëŸ¬ê°€ ë°œìƒí•œ ë¹ˆ ë”•ì…”ë„ˆë¦¬({}) í•„í„°ë§
        features = [f for f in features if f]
        if not features:
            logger.warning("Data collator received an empty batch.")
            return {}

        # pad_token_id ê°€ì ¸ì˜¤ê¸° (ì´ˆê¸°í™” ì‹œì ì— ì •í•´ì§)
        pad_token_id = self.tokenizer.tokenizer.pad_token_id

        # 1. í…ìŠ¤íŠ¸ ê´€ë ¨ í…ì„œ íŒ¨ë”©
        input_ids = pad_sequence(
            [f["input_ids"] for f in features],
            batch_first=True,
            padding_value=pad_token_id
        )
        labels = pad_sequence(
            [f["labels"] for f in features],
            batch_first=True,
            padding_value=-100  # ì†ì‹¤ ë§ˆìŠ¤í‚¹ ê°’ìœ¼ë¡œ íŒ¨ë”©
        )
        attention_mask = pad_sequence(
            [f["attention_mask"] for f in features],
            batch_first=True,
            padding_value=0  # ì–´í…ì…˜ ë§ˆìŠ¤í¬ëŠ” 0ìœ¼ë¡œ íŒ¨ë”©
        )

        batch = {
            "input_ids": input_ids,
            "attention_mask": attention_mask,
            "labels": labels,
        }

        # --- [BUG FIX] `image_grid_thw` ì œê±° ---
        # (IndexError: 0-dim tensor ë²„ê·¸ ìˆ˜ì •)

        return batch